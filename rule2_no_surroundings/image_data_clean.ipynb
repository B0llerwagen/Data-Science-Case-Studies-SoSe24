{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:30:17.536158Z",
     "start_time": "2024-06-20T13:30:04.901315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image 1613799667a9a83be42bc892838a9015c4cf015f0822045b.jpg with label 1\r"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "\n",
    "img_folder = \"../Yoio_Park_Proof\"\n",
    "target_size = (512, 512)\n",
    "label_data = read_csv(\"../local_data/balanced_labels_2.csv\", sep=\";\")\n",
    "\n",
    "'''\n",
    "# Function to load and resize an image\n",
    "def load_image(img_path, target_size):\n",
    "    with Image.open(img_path) as img:\n",
    "        img = img.resize(target_size)\n",
    "        img = img.convert('RGB')  # Ensure image is in RGB format\n",
    "        return np.array(img)\n",
    "        '''\n",
    "\n",
    "# Function to load, resize, and normalize an image using cv2\n",
    "def load_image(img_path, target_size):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Ensure image is in RGB format\n",
    "        img = img / 255.0  # Normalize image to the range [0, 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "# Read images and their corresponding labels\n",
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "for idx, row in label_data.iterrows():\n",
    "    img_name = row['Image_name']\n",
    "    img_path = os.path.join(img_folder, img_name)\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        img_array = load_image(img_path, target_size)\n",
    "        image_data.append(img_array)\n",
    "        image_labels.append(row[1])  # Assuming labels are in columns after 'Image'\n",
    "        print(f\"Loaded image {img_name} with label {row[1]}\", end='\\r')\n",
    "    else:\n",
    "        print(f\"Warning: Image {img_name} not found in folder {img_folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:30:17.544562Z",
     "start_time": "2024-06-20T13:30:17.537290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rule2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2262.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.340407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rule2\n",
       "count  2262.000000\n",
       "mean      0.340407\n",
       "std       0.473951\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:31:28.986926Z",
     "start_time": "2024-06-20T13:30:17.545163Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(image_data, image_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test)\n\u001b[1;32m      7\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_train)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data, image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:31:29.067569Z",
     "start_time": "2024-06-20T13:31:29.030481Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import to_categorical\n",
    "#normalize the images\n",
    "#X_train = np.array(X_train)/255.0\n",
    "#y_train = to_categorical(y_train, num_classes=2)\n",
    "#X_test = np.array(X_test)/255.0\n",
    "#y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:31:31.332497Z",
     "start_time": "2024-06-20T13:31:29.069820Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../local_data/test_img_2.pickle', 'wb') as f:\n",
    "    pickle.dump((X_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:31:33.637004Z",
     "start_time": "2024-06-20T13:31:31.334940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 10:31:28.677740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:32:40.435372Z",
     "start_time": "2024-06-20T13:31:33.637628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating done, generated 391  augmented images\n"
     ]
    }
   ],
   "source": [
    "#generate augmented images\n",
    "image_num = 2200 - len(X_train)\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "generated_count = 0\n",
    "\n",
    "\n",
    "for batch in datagen.flow(X_train, y_train, batch_size=1):\n",
    "  augmented_images.append(batch[0])\n",
    "  augmented_labels.append(batch[1])\n",
    "  generated_count += batch[0].shape[0]\n",
    "  print(\"Generated \", generated_count, \" augmented images\", end='\\r')\n",
    "  if generated_count >= image_num:\n",
    "    print(\"Generating done, generated\", image_num, \" augmented images\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:33:39.912523Z",
     "start_time": "2024-06-20T13:33:39.790558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((390, 512, 512, 3), (195, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array(augmented_labels).size)\n",
    "\n",
    "augmented_labels = augmented_labels[:-1]\n",
    "augmented_images = augmented_images[:-1]\n",
    "augmented_images = np.array(augmented_images).reshape(-1, 512, 512, 3)\n",
    "augmented_labels = np.array(augmented_labels).reshape(-1, 2)\n",
    "\n",
    "augmented_images.shape, augmented_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1808, 512, 512, 3), (904, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:-1]\n",
    "y_train = y_train[:-1]\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 2)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-20T13:32:40.864653Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#add x_train and augmented images together\u001b[39;00m\n\u001b[1;32m      2\u001b[0m augmented_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X_train, np\u001b[38;5;241m.\u001b[39marray(augmented_images)))\n\u001b[0;32m----> 3\u001b[0m augmented_labels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "#add x_train and augmented images together\n",
    "augmented_images = np.concatenate((X_train, np.array(augmented_images)))\n",
    "augmented_labels = np.concatenate((y_train, np.array(augmented_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../local_data/data_useable_2.pickle', 'wb') as f:\n",
    "    pickle.dump((augmented_images, augmented_labels), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(augmented_images[i].astype('uint8'))\n",
    "    axes[i].set_title(augmented_labels[i])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
