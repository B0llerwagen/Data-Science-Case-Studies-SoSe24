{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:53:57.069728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file='/Users/axxtur/Documents/Uni/Data-Science-Case-Studies-SoSe24/labels.csv'\n",
    "\n",
    "source_img_dir = '/Users/axxtur/Documents/Uni/Data-Science-Case-Studies-SoSe24/Yoio_Park_Proof'\n",
    "dest_img_dir ='/Users/axxtur/Documents/Uni/Data-Science-Case-Studies-SoSe24/first_tests_arthur/dataset'\n",
    "\n",
    "label_csv= pd.read_csv(labels_file,sep=';')\n",
    "\n",
    "img_names = label_csv['Image_name'].to_list()\n",
    "\n",
    "# Iterate through the list and copy images\n",
    "for image_name in img_names:\n",
    "    source_path = os.path.join(source_img_dir, image_name)\n",
    "    destination_path = os.path.join(dest_img_dir, image_name)\n",
    "    \n",
    "    # Check if the image exists in the source directory\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    else:\n",
    "        print(f\"Image not found: {image_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:55:04.501291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 812\n",
      "Train dataset size after mapping: 812\n",
      "Test dataset size after mapping: 204\n"
     ]
    }
   ],
   "source": [
    "###Prepare the Dataset\n",
    "# Function to load images\n",
    "def load_image(image_name, label):\n",
    "    image_name = image_name.numpy().decode('utf-8')\n",
    "    image_path = os.path.join(dest_img_dir, image_name)\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])  # Resize to match model input\n",
    "    return image, label\n",
    "\n",
    "# Create lists of image paths and labels\n",
    "image_paths = label_csv['Image_name'].tolist()\n",
    "labels = label_csv['Rule8'].tolist()\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert lists to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "print(f'Number of training images: {len(train_dataset)}')\n",
    "\n",
    "# Map function with debugging\n",
    "def map_function(image_name, label):\n",
    "    image, label = tf.py_function(func=load_image, inp=[image_name, label], Tout=[tf.float32, tf.int32])\n",
    "    image.set_shape((224, 224, 3))\n",
    "    label.set_shape([])\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(map_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(map_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Verify the dataset sizes after mapping\n",
    "print(f'Train dataset size after mapping: {len(list(train_dataset))}')\n",
    "print(f'Test dataset size after mapping: {len(list(test_dataset))}')\n",
    "\n",
    "# Batch and prefetch the datasets -> \n",
    "train_dataset = train_dataset.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "### Data Argumentation\n",
    "# Data augmentation (optional but recommended)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Apply data augmentation to the training dataset\n",
    "def augment(image, label):\n",
    "    return data_augmentation(image, training=True), label\n",
    "\n",
    "train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Model\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(224, 224, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Adjust the number of classes as per your labels\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 65s 2s/step - loss: 26.0136 - accuracy: 0.8239 - val_loss: 0.3437 - val_accuracy: 0.9118\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 60s 2s/step - loss: 0.3524 - accuracy: 0.9261 - val_loss: 0.2734 - val_accuracy: 0.9118\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.2793 - accuracy: 0.9261 - val_loss: 0.2733 - val_accuracy: 0.9118\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 44s 2s/step - loss: 0.2544 - accuracy: 0.9261 - val_loss: 0.2784 - val_accuracy: 0.9118\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 42s 2s/step - loss: 0.2641 - accuracy: 0.9261 - val_loss: 0.2775 - val_accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "### Train the Model\n",
    "\n",
    "history = model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 540ms/step - loss: 0.2775 - accuracy: 0.9118\n",
      "Test Accuracy: 0.9117646813392639\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "                                           image_name  predicted_class\n",
      "0   1588102754ef37b75534a067b80853684366db49f9cd54...                0\n",
      "1   16111409184380c4bb8020ad9d6f29dc51ffa9e614baf2...                0\n",
      "2   16097735485deba827a70b144707dcd5f7fdcd399478cc...                0\n",
      "3   1605814493efb019e9c5f23b08bd924c0dd4b4fe1682d3...                0\n",
      "4   15984641483deec9931b094b48c97483dff6a3a301f513...                0\n",
      "..                                                ...              ...\n",
      "95  1600095908eca13bfe5f77cc824324f00aee01471e75aa...                0\n",
      "96  1594271635fb4062a23bfce5c3a5e42f1c9c5994bee628...                0\n",
      "97  160898569319c6f0eb56511c40b92da66a711f5d0a4525...                0\n",
      "98  1588353652adbf6b5069e72d45483907e74a16c90b2474...                0\n",
      "99  1605640153820b2b93a51aa86dc47b373150e92414ce99...                0\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Copied 1588102754ef37b75534a067b80853684366db49f9cd54dd.jpg to predictions_0\n",
      "Copied 16111409184380c4bb8020ad9d6f29dc51ffa9e614baf22a.jpg to predictions_0\n",
      "Copied 16097735485deba827a70b144707dcd5f7fdcd399478cc66.jpg to predictions_0\n",
      "Copied 1605814493efb019e9c5f23b08bd924c0dd4b4fe1682d377.jpg to predictions_0\n",
      "Copied 15984641483deec9931b094b48c97483dff6a3a301f51341.jpg to predictions_0\n",
      "Copied 1614176047f9262c773ba8c6abba9ee8d42306fedf2d4547.jpg to predictions_0\n",
      "Copied 1592995336d56dbcab465a91a163678f923fc2f770707817.jpg to predictions_0\n",
      "Copied 1605719077b43317b25409cd86979b5a3a944e24327606af.jpg to predictions_0\n",
      "Copied 1607538335e43a55b71cd8475788f3bbc2edc5004a81b0c9.jpg to predictions_0\n",
      "Copied 1605704838fc4538620b4c8e08117babb212505f5f53bbf5.jpg to predictions_0\n",
      "Copied 16013270576b873cb8601139ff25f3d83c91d5441f22af54.jpg to predictions_0\n",
      "Copied 1597417309934e1e4d0d28fd580ceef0a982927ea76fb623.jpg to predictions_0\n",
      "Copied 1614514780e581f2a674a379343072e24c77ada03bb388f3.jpg to predictions_0\n",
      "Copied 16089128341e4fc27365e69281b6d284b0e3008a9ea0615f.jpg to predictions_0\n",
      "Copied 1593330238bd7d96f1aa138aa1577e5c2adf3ed88e9b4e23.jpg to predictions_0\n",
      "Copied 16040061114bf64aa0e7812a07dc0c68a43e0f2db81da66e.jpg to predictions_0\n",
      "Copied 15862833938ee6993b830a714d54ede5117c3840c6410818.jpg to predictions_0\n",
      "Copied 1602739480767e953e69d2ef67474f667b6398410a167210.jpg to predictions_0\n",
      "Copied 161368138375d8f4fb8c7c4bcdbf1510adcc6ed84f5c20b5.jpg to predictions_0\n",
      "Copied 1608400127fb9c44e0f5e8b275756d0a214718d427f430fa.jpg to predictions_0\n",
      "Copied 1607015221c5a7de96983de23e380bcf58cc61c28fdac0a2.jpg to predictions_0\n",
      "Copied 1599142765a51d7a80049026646f23add7dd57fec3217b40.jpg to predictions_0\n",
      "Copied 159161303607fff9710abe7b7aee9f8540d33b080d5fd82d.jpg to predictions_0\n",
      "Copied 1596225992d10b99e872d99ae295bd6e33f005367ea22933.jpg to predictions_0\n",
      "Copied 160737059361d1387a2874322c5b133cab407083bc373997.jpg to predictions_0\n",
      "Copied 15856766299e9a9591e9a51fc664c4ff9786ab34b8d3d949.jpg to predictions_0\n",
      "Copied 16008656103a51144b5f3c9a526e1f5e9d0a7c427874ec8b.jpg to predictions_0\n",
      "Copied 1598248610f5eadb120110cb22f98e1d15225ea4ed591d97.jpg to predictions_0\n",
      "Copied 1611422991adcc641a517faced6da2608ca602483d1c89a4.jpg to predictions_0\n",
      "Copied 1608057131f674b1fa0c0cbaa5f401eb17e3ec2833a357cc.jpg to predictions_0\n",
      "Copied 15955181618c7756bfd39769bc084347c0c9adbe00ed2cab.jpg to predictions_0\n",
      "Copied 16076709568c6312bf1f4759cf3abae6dff9335646ad8197.jpg to predictions_0\n",
      "Copied 16121164517d3e6b67ed2140a948820fe86b5983bb7ebbeb.jpg to predictions_0\n",
      "Copied 1598708577b09eaad1d5b8381aaab320f303370de746c469.jpg to predictions_0\n",
      "Copied 1584540427020454d955f0f1f84211e2e64abd26ff2c6f6b.jpg to predictions_0\n",
      "Copied 1605977941b6b2ad316e43689219af7be994bd12579c4124.jpg to predictions_0\n",
      "Copied 161080833094cd4f38a5d52b362f4c994b47520687f63259.jpg to predictions_0\n",
      "Copied 16016720630fdc0f7b0ffe8cba98168188be64fcb997788f.jpg to predictions_0\n",
      "Copied 16007492914f878109211901604468c59376cdfd1af671f2.jpg to predictions_0\n",
      "Copied 1615028282cd7a93954242f5bd841c95e9fdf631e300c627.jpg to predictions_0\n",
      "Copied 1591632053e4e0dc32bee6745502e56afdd5d15e7e5cc6fa.jpg to predictions_0\n",
      "Copied 1612822938e5947a5c222793748a869b19ec9c6cd0331ec0.jpg to predictions_0\n",
      "Copied 161237785048c3202fa729095bbb6e8080d388596aa4ab34.jpg to predictions_0\n",
      "Copied 16145191379fd979299da7c77b3a9bdf7d66580389e5bcb5.jpg to predictions_0\n",
      "Copied 16071821663e0fc7155004beff6fedf224486bea49037cd9.jpg to predictions_0\n",
      "Copied 1595002021dea39f96185fcd81874432e4719f31dea252b8.jpg to predictions_0\n",
      "Copied 1590953930e8b6b3ea8176696bcdbb50d4cf575b385134d3.jpg to predictions_0\n",
      "Copied 159699543990eb5406899b733656a06d966c722e49ac8943.jpg to predictions_0\n",
      "Copied 16105463609c3ed14d5475fc799a6caa40bf6ccc07d57bee.jpg to predictions_0\n",
      "Copied 160058736274022cf2f801c77f094015bfcc360a4536d856.jpg to predictions_0\n",
      "Copied 158729984751c4974f56937b36393da2b0cfb99a9081ff7f.jpg to predictions_0\n",
      "Copied 16082731803b5dfb7710a2243215d2ada96200623b5105b7.jpg to predictions_0\n",
      "Copied 16055050635c6270d755cd7d396d97c7b8e75348795abdea.jpg to predictions_0\n",
      "Copied 16149271548e47ece725344133f6b28eefaa154bc0a36511.jpg to predictions_0\n",
      "Copied 1613727997ca3aa0fc04a539198f2a552a516003cc0550a9.jpg to predictions_0\n",
      "Copied 16077087441d8c395d12aa2819c055ef6ae362bda6f4cf65.jpg to predictions_0\n",
      "Copied 1584467019e81a0ea97641ff3bbf7c96e781e6bb455bd621.jpg to predictions_0\n",
      "Copied 158634677570246d157aa013a2ed6081476ceeb1c19b54d7.jpg to predictions_0\n",
      "Copied 160425415810cedcb69a6a0f0487a65e5b6dc574a7033255.jpg to predictions_0\n",
      "Copied 1597155031575bdabc0bb58fb77856bc05c856e59b4170d2.jpg to predictions_0\n",
      "Copied 16060543755d2f84b98258cc1311c0f91085d4715960f6e7.jpg to predictions_0\n",
      "Copied 160112923964d18744c3e66b3aafa177cad1068ade1edd8f.jpg to predictions_0\n",
      "Copied 1604641062c173544b01df24e778a896742ef5232e94237c.jpg to predictions_0\n",
      "Copied 16016654420f50d24b5cd3e647af4027a467b669b6ea23d4.jpg to predictions_0\n",
      "Copied 16147756176ca2fe2ec15c8e770d4c56ead307d3c4344953.jpg to predictions_0\n",
      "Copied 1609424741362bdea6b0ff309ebebe93e916b73f4f1fc39b.jpg to predictions_0\n",
      "Copied 1603727237bfe19b69a6a8235812c02929d43eacbb3d8da5.jpg to predictions_0\n",
      "Copied 1605983389c8654b11b0d66d7f1039155c651803af2550ba.jpg to predictions_0\n",
      "Copied 158632359971e53aab0cb2bc17984e1d8882352b554d4d38.jpg to predictions_0\n",
      "Copied 1615295671367a8e8c3fa65c6afafc18c47eeac8af297218.jpg to predictions_0\n",
      "Copied 1615142414fa606d85bd2642bb4e35ba9a0704931a5b0abb.jpg to predictions_0\n",
      "Copied 161116202503a4c64b67de48ecd8c625efe39fa45ac3163c.jpg to predictions_0\n",
      "Copied 1610375108601f698ceb536767128889c6fb22e00ccd205b.jpg to predictions_0\n",
      "Copied 1602337573c300ca21bb3de74a69d87541298701d2f8730e.jpg to predictions_0\n",
      "Copied 1613852992091d7ee9aa467981bc8cd9a143867f53a9f3f7.jpg to predictions_0\n",
      "Copied 16142958794a6e47f935956ab5d6d1cd29fb1f61eed477e5.jpg to predictions_0\n",
      "Copied 15980371340b089fb05dc2a99787c3853623b834730a3ec2.jpg to predictions_0\n",
      "Copied 160054359208f63096f5b7c4a7edf9fc07be4c994e3faa1c.jpg to predictions_0\n",
      "Copied 1612705897e2f07a0d34a2a9da0d7f09a36726986afc0474.jpg to predictions_0\n",
      "Copied 1606255195a8607184a125ea5fb5198f38f64eddd8cf4e54.jpg to predictions_0\n",
      "Copied 1614225049018ea3e70672f08ec65342934f70cea18895de.jpg to predictions_0\n",
      "Copied 16140180069e58b43fb7208ba5eceae9982d920a53b39e34.jpg to predictions_0\n",
      "Copied 16112126391359137cf5f3c2c5cb500257d29d1505acc942.jpg to predictions_0\n",
      "Copied 15942279881293811714cdf7535467602092a6e31b3fe6c2.jpg to predictions_0\n",
      "Copied 1601211661f39d139f6b6bf8fb6033f18db41a39187a6df3.jpg to predictions_0\n",
      "Copied 15987822250595b826bae42c52cad9dd53cf86ffc4c30145.jpg to predictions_0\n",
      "Copied 1598028695fce3a2273ddfcd5b5500d3c1395932143df83b.jpg to predictions_0\n",
      "Copied 16019069677c219e0718c56ff9fef0974f48f9ce4ed45268.jpg to predictions_0\n",
      "Copied 1607623529004e0441506d2a3ccb43f09565c0943d9399cd.jpg to predictions_0\n",
      "Copied 15918081508a597714473d2fe9db1fc60aa72820da597094.jpg to predictions_0\n",
      "Copied 1595497625006b938260e8fdc6f3f32cfc7c7cc467be5f7d.jpg to predictions_0\n",
      "Copied 160000172872457dbbc5ad01e4ecfe7b976c0ada35e6a578.jpg to predictions_0\n",
      "Copied 16006843105c3ddbdec8c584468434544f7512ce7a349b57.jpg to predictions_0\n",
      "Copied 16138727677c7d9195e559f5692f2b01a909733d8687d682.jpg to predictions_0\n",
      "Copied 16057984532814ace2fd67f4d6ce5537653ca55d14a10f2a.jpg to predictions_0\n",
      "Copied 1600095908eca13bfe5f77cc824324f00aee01471e75aaca.jpg to predictions_0\n",
      "Copied 1594271635fb4062a23bfce5c3a5e42f1c9c5994bee628f7.jpg to predictions_0\n",
      "Copied 160898569319c6f0eb56511c40b92da66a711f5d0a452577.jpg to predictions_0\n",
      "Copied 1588353652adbf6b5069e72d45483907e74a16c90b2474f3.jpg to predictions_0\n",
      "Copied 1605640153820b2b93a51aa86dc47b373150e92414ce9939.jpg to predictions_0\n"
     ]
    }
   ],
   "source": [
    "### Precict Images\n",
    "def predict_new_images(model, image_folder, num_images=100):\n",
    "    random_images = random.sample(os.listdir(image_folder), num_images)\n",
    "    results = []\n",
    "    \n",
    "    for image_name in random_images:\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])  # Resize to match model input\n",
    "        image = tf.expand_dims(image, 0)  # Add a batch dimension\n",
    "        predictions = model.predict(image)\n",
    "        predicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "        results.append((image_name, predicted_class))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Specify the folder containing new images\n",
    "predictions_folder_0 = 'predictions_0'\n",
    "predictions_folder_1 = 'predictions_1'\n",
    "\n",
    "# Create the predictions folder if it doesn't exist\n",
    "os.makedirs(predictions_folder_0, exist_ok=True)\n",
    "os.makedirs(predictions_folder_1, exist_ok=True)\n",
    "\n",
    "# Predict the class for 10 random images from the new image folder\n",
    "predicted_results = predict_new_images(model, source_img_dir)\n",
    "predicted_df = pd.DataFrame(predicted_results, columns=['image_name', 'predicted_class'])\n",
    "\n",
    "print(predicted_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "predicted_df.to_csv('predicted_results.csv', index=False)\n",
    "\n",
    "# Copy the predicted images to the predictions folder\n",
    "for index, row in predicted_df.iterrows():\n",
    "    image_name = row['image_name']\n",
    "    predicted_class = row['predicted_class']\n",
    "    src_path = os.path.join(source_img_dir, image_name)\n",
    "    dst_path_0 = os.path.join(predictions_folder_0, image_name)\n",
    "    dst_path_1 = os.path.join(predictions_folder_1, image_name)\n",
    "    if predicted_class == 1:\n",
    "        shutil.copy(src_path, dst_path_1)\n",
    "        print(f'Copied {image_name} to {predictions_folder_1}')\n",
    "    \n",
    "    if predicted_class == 0:\n",
    "        shutil.copy(src_path, dst_path_0)\n",
    "        print(f'Copied {image_name} to {predictions_folder_0}')\n",
    "\n",
    "# Verify the copied images\n",
    "#print(f'Copied images: {os.listdir(predictions_folder)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
